{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import pandas as pd\n",
    "import math\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Links From List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_computer_scientists\"\n",
    "\n",
    "\n",
    "response = requests.get(url)\n",
    "first_links_list = []\n",
    "\n",
    "if response.status_code == 200:\n",
    "    \n",
    " soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    \n",
    " h2_element = soup.find('div', {'class': 'mw-content-ltr mw-parser-output'})\n",
    " list_test=h2_element.find_all('ul')\n",
    "\n",
    " for ul_element in list_test:\n",
    "      li_elements = ul_element.find_all('li')\n",
    "      for li in li_elements:\n",
    "            link = li.find('a')\n",
    "            if link:\n",
    "                href = link.get('href')\n",
    "                if href:\n",
    "                    full_link = f\"https://en.wikipedia.org{href}\"\n",
    "                    first_links_list.append(full_link)\n",
    " links_to_exclude = []\n",
    " see_also_header = soup.find('span',id='See_also').parent\n",
    " see_also_div = see_also_header.find_next('div')\n",
    " see_also_ul = see_also_div.find_all('ul')\n",
    " for ul_element in see_also_ul:\n",
    "      see_also_li_elements = ul_element.find_all('li')\n",
    "      for li in see_also_li_elements:\n",
    "        link = li.find('a')\n",
    "        if link:\n",
    "            href = link.get('href')\n",
    "            if href:\n",
    "                full_link = f\"https://en.wikipedia.org{href}\"\n",
    "                links_to_exclude.append(full_link)\n",
    "first_links_list = [link for link in first_links_list if link not in links_to_exclude]\n",
    "print(first_links_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scientist_name(link):\n",
    "    response= requests.get(link)\n",
    "    if response.status_code == 200:\n",
    "    \n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        name=soup.find('span',{'class': 'mw-page-title-main'}).text\n",
    "        if name:\n",
    "            return name\n",
    "        else:\n",
    "            return 'unknown'       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Awards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scientist_awards(link):\n",
    "    response= requests.get(link)\n",
    "    if response.status_code == 200:\n",
    "        \n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        find_awards=0\n",
    "        awards_table = soup.find('table',{'class': 'infobox biography vcard'})\n",
    "        if(awards_table):\n",
    "            awards_table_condition = awards_table.find('th', string= 'Awards')\n",
    "            if awards_table_condition:\n",
    "                awards_table_td = awards_table_condition.find_next('td',{'class' : 'infobox-data'})\n",
    "                awards_table_list = awards_table_td.find_next('ul')\n",
    "                awards=len(awards_table_list.find_all('li'))\n",
    "                find_awards=1\n",
    "\n",
    "        if find_awards==0:\n",
    "            awards_header_condition = soup.find('span', {'id': 'Honors_&_Awards'})\n",
    "            if awards_header_condition:\n",
    "                awards_header = soup.find('span', {'id': 'Honors_&_Awards'}).parent\n",
    "                awards_list=awards_header.find_next('ul')\n",
    "                li_elements = list(awards_list.find_all('li'))\n",
    "                awards=len(li_elements)\n",
    "                find_awards=1\n",
    "        \n",
    "        if find_awards==1:\n",
    "             return awards\n",
    "        else:\n",
    "             return 0               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scientist_education(link):\n",
    "    response= requests.get(link)\n",
    "    if response.status_code == 200:\n",
    "    \n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        find_education=0\n",
    "        education_table = soup.find('table',{'class': 'infobox biography vcard'})\n",
    "        if education_table:\n",
    "            education_table_condition = education_table.find('th', string= 'Education')\n",
    "            if education_table_condition:\n",
    "                education_header= education_table_condition.parent\n",
    "                education_table_td = education_header.find_next('td')\n",
    "                education_list = education_table_td.find_next('> ul')\n",
    "                if education_list:\n",
    "                    education_text = ', '.join(li.get_text(strip=True) for li in ul_element.find_all('li'))\n",
    "                    find_education=1\n",
    "                education_a = education_table_td.find_all('a')\n",
    "                if education_a and find_education==0:\n",
    "                    education_text = ', '.join(a.get_text(strip=True) for a in education_table_td.find_all('a'))\n",
    "                    find_education=1\n",
    "            if find_education==0:\n",
    "                alma_matter_condition = education_table.find('th', string= 'Alma mater')\n",
    "                if alma_matter_condition:\n",
    "                    alma_matter_header = alma_matter_condition.parent\n",
    "                    alma_matter_td = alma_matter_header.find_next('td')\n",
    "                    alma_matter_list = alma_matter_td.find_next('> ul')\n",
    "                    if alma_matter_list:\n",
    "                        education_text = ', '.join(li.get_text(strip=True) for li in ul_element.find_all('li'))\n",
    "                        find_education=1\n",
    "\n",
    "                    alma_matter_a = alma_matter_td.find_all('a')\n",
    "                    if alma_matter_a and find_education==0 :\n",
    "                        education_text = ', '.join(a.get_text(strip=True) for a in alma_matter_td.find_all('a'))\n",
    "                        find_education=1\n",
    "\n",
    "        if find_education==1:\n",
    "            return education_text\n",
    "        else:\n",
    "             return 'NO_SAVE'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Into the CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sv_filename = 'scientists_data.csv'\n",
    "\n",
    "# # Headers\n",
    "# headers = ['Name', 'Awards', 'Education']\n",
    "\n",
    "# with open(csv_filename, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "    \n",
    "#    csv_writer = csv.writer(csv_file)\n",
    "\n",
    "#    # Write the headers \n",
    "#    csv_writer.writerow(headers)\n",
    "\n",
    "#    #write each scientist's information to the CSV file\n",
    "#    for link in first_links_list:\n",
    "#        name = get_scientist_name(link)\n",
    "#        awards = get_scientist_awards(link)\n",
    "#        education = get_scientist_education(link)\n",
    "      \n",
    "\n",
    "#        #Write the information\n",
    "#        if education!='NO_SAVE' and not education.startswith('(') and not education.startswith('['):\n",
    "#            csv_writer.writerow([name, awards, education])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Garbage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Name  Awards   \n",
      "0    Atta ur Rehman Khan      10  \\\n",
      "1         Scott Aaronson       4   \n",
      "2           Rediet Abebe       3   \n",
      "3            Hal Abelson       1   \n",
      "4        Serge Abiteboul       4   \n",
      "..                   ...     ...   \n",
      "504       Stanley Zdonik       0   \n",
      "505        Hussein Zedan       0   \n",
      "506   Shlomo Zilberstein       0   \n",
      "507       Jill Zimmerman       0   \n",
      "508          Konrad Zuse       5   \n",
      "\n",
      "                                             Education  \n",
      "0             University of Malaya, COMSATS University  \n",
      "1    Cornell University, University of California, ...  \n",
      "2    Cornell University, University of Cambridge, H...  \n",
      "3    Princeton University, Massachusetts Institute ...  \n",
      "4                    University of Southern California  \n",
      "..                                                 ...  \n",
      "504              Massachusetts Institute of Technology  \n",
      "505                              University of Bristol  \n",
      "506  University of California, Berkeley, Technion –...  \n",
      "507         Purdue University, University of Minnesota  \n",
      "508                     Technical University of Berlin  \n",
      "\n",
      "[509 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "csv_file_path = 'scientists_data.csv'\n",
    "df = pd.read_csv(csv_file_path)\n",
    "all_institutes=[]\n",
    "for row in df['Education']:\n",
    "    institutes = [inst.strip() for inst in row.split(',')]\n",
    "    all_institutes.extend(institutes)\n",
    "\n",
    "unique_institutes = list(set(all_institutes))\n",
    "unique_institutes.remove('Ph.D')\n",
    "unique_institutes.remove('B.S.')\n",
    "unique_institutes.remove('[11]')\n",
    "unique_institutes.remove('[2]')\n",
    "unique_institutes.remove('S.B.')\n",
    "unique_institutes.remove('BSc.')\n",
    "unique_institutes.remove('es')\n",
    "unique_institutes.remove('BE')\n",
    "unique_institutes.remove('[1]')\n",
    "unique_institutes.remove('[3]')\n",
    "unique_institutes.remove('[5]')\n",
    "unique_institutes.remove('PhD')\n",
    "unique_institutes.remove('[4]')\n",
    "unique_institutes.remove('MSc')\n",
    "unique_institutes.remove('B.Sc.')\n",
    "unique_institutes.remove('BSc')\n",
    "unique_institutes.remove('BASc')\n",
    "unique_institutes.remove('Ph.D.')\n",
    "unique_institutes.remove('1969')\n",
    "unique_institutes.remove('MS')\n",
    "unique_institutes.remove('M.S.')\n",
    "unique_institutes.remove('SM')\n",
    "unique_institutes.remove('BS')\n",
    "unique_institutes.remove('SB')\n",
    "unique_institutes.remove('BA')\n",
    "unique_institutes.remove('AB')\n",
    "unique_institutes.remove('B.A.')\n",
    "unique_institutes.remove('Diplom')\n",
    "unique_institutes.remove('')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class peer_node:\n",
    "    def __init__(self,df,node_num):\n",
    "        self.values=df\n",
    "        self.node_num=node_num\n",
    "        self.predecessor=0\n",
    "        self.fingertable = pd.DataFrame(columns=['successors', 'index_of_peers'])\n",
    "        self.key=[]\n",
    "    def set_key(self,key):\n",
    "        self.key=key\n",
    "    def get_key(self,key):\n",
    "        self.key.append(key)\n",
    "    def merge_key_list(self,node2):\n",
    "        self.key=self.key+node2.key\n",
    "    def set_finger(self,succ,index):\n",
    "        self.fingertable['successors'] = succ\n",
    "        self.fingertable['index_of_peers'] = index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chord Cirlce Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chord_circle:\n",
    "    def __init__(self,institutes,df):\n",
    "        self.institutes=institutes\n",
    "        self.df=df\n",
    "        self.max_node=0\n",
    "        self.peers=[]\n",
    "        self.fake_hash_table=pd.DataFrame(columns=['number_of_key','key','search_key'])\n",
    "    def remove_finger_tables(self):\n",
    "        for peer in self.peers:\n",
    "            peer.fingertable=pd.DataFrame(columns=['successors', 'index_of_peers'])\n",
    "    def create_finger_table_for_all(self):\n",
    "        length=len(self.peers)\n",
    "        m=math.ceil(math.log2(length))\n",
    "        temp_start=0\n",
    "        for peer in self.peers:\n",
    "            temp_table=[]\n",
    "            index_table=[]\n",
    "            first_attempt=0\n",
    "            for i in range(1,m+1):\n",
    "                ok=0\n",
    "                start=peer.node_num+2**(i-1)\n",
    "                #if peer.node_num==405:\n",
    "                    #print(\"FINGERTABLE-->\"+ str(start)+ \" WITH MAXNODE--> \"+str(self.max_node)) #DEBUGGING\n",
    "                if start > self.max_node:\n",
    "                    start= start - self.max_node -1\n",
    "                if (self.return_to_start(peer.node_num)) & (first_attempt==0):\n",
    "                    #print(\"THIS IS NODE_NUM--> \"+str(peer.node_num)) #DEBUGGING\n",
    "                    start=0\n",
    "                    first_attempt=1\n",
    "                while(ok==0):\n",
    "                    for index,s_peer in enumerate(self.peers):\n",
    "                        if s_peer.node_num==start:\n",
    "                            temp_table.append(start)\n",
    "                            index_table.append(index)\n",
    "                            ok=1\n",
    "                    start+=1\n",
    "               \n",
    "            peer.set_finger(temp_table,index_table) \n",
    "    def renew_max_node(self):\n",
    "        self.max_node=int(self.peers[len(self.peers)-1].node_num)\n",
    "        #print(\"TYPE OF MAX NODE -->\"+str(self.max_node))\n",
    "        #print(\"NEW MAX NODE --> \"+str(self.max_node)) DEBUGGING\n",
    "    def create_list_of_peers(self):\n",
    "        counter=0\n",
    "\n",
    "        for institute in self.institutes:\n",
    "            result_rows = []\n",
    "            self.fake_hash_table.loc[len(self.fake_hash_table)] = {'number_of_key': counter, 'key': institute,'search_key': counter}\n",
    "\n",
    "            for index, row in self.df.iterrows():\n",
    "        \n",
    "                if institute in row['Education']:\n",
    "                    result_rows.append(row.drop('Education'))\n",
    "\n",
    "\n",
    "            result_df = pd.DataFrame(result_rows).reset_index(drop=True)\n",
    "            result_df['institute'] = institute\n",
    "            peer=peer_node(result_df,counter)\n",
    "            counter+=1\n",
    "            peer.get_key(institute)\n",
    "            self.peers.append(peer)\n",
    "        self.renew_max_node()\n",
    "        self.create_finger_table_for_all()\n",
    "    def return_to_start(self,i):\n",
    "        #print(\"MAX=\"+str(self.max_node)) DEBUGGING\n",
    "        if (i != 0) & ((i %  self.max_node) == 0):\n",
    "            return 1 \n",
    "        else:\n",
    "            return 0\n",
    "    def key_to_number(self,lookup_key):\n",
    "        get_num=None\n",
    "        for index,row in self.fake_hash_table.iterrows():\n",
    "            if row['key'].lower()==lookup_key.lower():\n",
    "                get_num=row['search_key']\n",
    "                #print('SEARCH KEY IS --->'+str(get_num)) DEBUGGING\n",
    "                break\n",
    "        if get_num==None:\n",
    "            print(\"No archive for this Institute\")\n",
    "        return get_num\n",
    "        #print(get_num) DEBUGGING\n",
    "    def lookup(self,key,threshold):\n",
    "        node_to_search=self.key_to_number(key)\n",
    "        print(f\"The key is --> {node_to_search}\")\n",
    "        #print('I WANT NODE'+str(node_to_search)) DEBUGGING\n",
    "        if node_to_search!=None:\n",
    "            res_df=pd.DataFrame()\n",
    "            this_node=self.peers[0]\n",
    "            while(this_node.node_num!=node_to_search):\n",
    "                print(f\"Searching {this_node.node_num} fingertable\")\n",
    "                ft=this_node.fingertable['successors']\n",
    "                print(f\"{ft}\") #DEBUGGING\n",
    "                for index,row in this_node.fingertable.iterrows():\n",
    "                    if row['successors']==node_to_search:\n",
    "                        #print('1st if-->'+str(row['successors']))  #DEBBUGING\n",
    "                            index=row['index_of_peers']\n",
    "                            this_node=self.peers[index]\n",
    "                            break\n",
    "                        \n",
    "                    elif row['successors']>node_to_search :\n",
    "                        #print('2nd if') #DEBUGGING\n",
    "                        this_node_index = index - 1\n",
    "                        if this_node_index >= 0:\n",
    "                            previous_row = this_node.fingertable.at[this_node_index, 'index_of_peers']\n",
    "                            print_row = this_node.fingertable.at[this_node_index, 'successors']\n",
    "                            print(f'Previous_row = {print_row}')\n",
    "                            this_node=self.peers[previous_row]\n",
    "                            break\n",
    "                    else:\n",
    "                        #print('3rd if') #DEBUGGING\n",
    "                        if index == this_node.fingertable.index[-1]:\n",
    "                            print_this=this_node.fingertable['successors'].max()\n",
    "                            print(f'Max row = {print_this}')\n",
    "                            correct_index=this_node.fingertable['index_of_peers'].max()\n",
    "                            this_node=self.peers[correct_index]\n",
    "                        else: continue\n",
    "               \n",
    "            res_df=this_node.values\n",
    "            filtered_rows = res_df[(res_df['Awards'] >= threshold) & (res_df['institute']==key)]\n",
    "            print(filtered_rows)\n",
    "    def leave_circle(self,node):\n",
    "        big=1\n",
    "        for peer in self.peers:\n",
    "            if peer.node_num==node:\n",
    "                delete_this_node=peer\n",
    "                big=0\n",
    "        if big==1:\n",
    "            print('There is no such node')\n",
    "        elif node<=self.max_node:\n",
    "            #if self.return_to_start(node):\n",
    "                nn = delete_this_node.fingertable['index_of_peers'].iloc[0]\n",
    "                print(f'NN is -->{nn}')\n",
    "                next_node=self.peers[nn]\n",
    "                next_node.values=pd.concat([next_node.values,delete_this_node.values],ignore_index=True)\n",
    "                next_node.merge_key_list(delete_this_node)\n",
    "                self.fake_hash_table.loc[self.fake_hash_table['search_key']==node,'search_key']=next_node.node_num                    \n",
    "        \n",
    "                self.peers.remove(delete_this_node)\n",
    "                self.renew_max_node()\n",
    "                self.remove_finger_tables()\n",
    "                self.create_finger_table_for_all()\n",
    "    def show(self):\n",
    "        for peer in self.peers:\n",
    "            key_str = ', '.join(map(str, peer.key))\n",
    "            print(str(peer.node_num) + ' --> ' + key_str)\n",
    "    def join_circle(self):\n",
    "        empty_slots=[]\n",
    "        last=0\n",
    "        max_empty=self.fake_hash_table['number_of_key'].iloc[-1]\n",
    "        stop=max_empty+1\n",
    "        if max_empty==self.max_node:\n",
    "            stop=stop+1\n",
    "        for i in range(0,stop):\n",
    "            if i>self.max_node:\n",
    "                empty_slots.append(i)\n",
    "            elif i<len(self.peers)-1:\n",
    "                #print(self.peers[i].node_num) DEBUGGING\n",
    "                #print(f'Max node is {self.max_node} and i is {i+1}')\n",
    "                D=self.peers[i+1].node_num-self.peers[i].node_num\n",
    "                if D>1 : \n",
    "                    for j in range(self.peers[i].node_num+1,self.peers[i+1].node_num):\n",
    "                        empty_slots.append(j)\n",
    "        print(\"Choose a slot from these:\")\n",
    "        for slot in empty_slots:\n",
    "            print(slot)\n",
    "        sys.stdout.flush() \n",
    "        chosen_node=int(input(\"Enter here ---> \"))\n",
    "        print(chosen_node)\n",
    "        if chosen_node not in empty_slots:\n",
    "            print(\"Thats not a valid node!\")\n",
    "        elif chosen_node==max(empty_slots) &  self.fake_hash_table['number_of_key'].iloc[-1]!=chosen_node:\n",
    "            empty_df=pd.DataFrame()\n",
    "            peer_n=peer_node(empty_df,chosen_node)\n",
    "            self.peers.append(peer_n)\n",
    "        else:\n",
    "            new_keys=[]\n",
    "            new_node_df=pd.DataFrame()\n",
    "            pre=chosen_node-1\n",
    "            while pre in empty_slots and pre>=0:\n",
    "                pre=pre-1\n",
    "            if chosen_node==max(empty_slots):\n",
    "                next_node_num=self.peers[0].node_num\n",
    "                last=1\n",
    "            else:\n",
    "                suc=chosen_node+1\n",
    "                while suc in empty_slots:\n",
    "                    suc=suc+1\n",
    "                next_node_num=suc\n",
    "                while pre in empty_slots and pre>=0:\n",
    "                    pre=pre-1\n",
    "                    if pre<0:\n",
    "                        pre=self.max_node\n",
    "                \n",
    "            self.fake_hash_table.loc[(self.fake_hash_table['number_of_key'] <= chosen_node) & (self.fake_hash_table['number_of_key'] >pre), 'search_key'] = chosen_node\n",
    "            condition=(self.fake_hash_table['search_key'] <= chosen_node) & (self.fake_hash_table['search_key'] >pre)\n",
    "            selected_rows = self.fake_hash_table[condition]\n",
    "            print(selected_rows)\n",
    "            list_try=selected_rows['key'].tolist()\n",
    "            for peer in self.peers:\n",
    "                if peer.node_num==next_node_num:\n",
    "                    split_condition = peer.values['institute'].isin(list_try)\n",
    "                    new_node_df=peer.values[split_condition]\n",
    "                    peer.values=peer.values[~split_condition]\n",
    "                    peer_index=self.peers.index(peer)\n",
    "                    for key in list_try:\n",
    "                        new_keys.append(key)\n",
    "                        peer.key.remove(key)\n",
    "                    #print(peer.values)\n",
    "            # self.peers(next_node).value\n",
    "            peer_n=peer_node(new_node_df,chosen_node)\n",
    "            peer_n.set_key(new_keys)\n",
    "            if last==1:\n",
    "                print(new_node_df)\n",
    "                self.peers.append(peer_n)\n",
    "            else:\n",
    "                self.peers.insert(peer_index,peer_n)\n",
    "        self.renew_max_node()\n",
    "        self.remove_finger_tables()\n",
    "        self.create_finger_table_for_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Δημιουργία αντικειμένου\n",
    "### Δημιουργία Chord Circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "Chord=Chord_circle(unique_institutes,df)\n",
    "Chord.create_list_of_peers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Εμφάνιση κύκλου"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Chord.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Εμφάνιση fake_hash_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     number_of_key                                  key  search_key\n",
      "0                0                  Harvey Mudd College           0\n",
      "1                1       Indian Institute of Technology           1\n",
      "2                2                     Brock University           2\n",
      "3                3                       Rhodes College           3\n",
      "4                4                University of Alberta           4\n",
      "..             ...                                  ...         ...\n",
      "402            402           Instituto Superior Técnico         402\n",
      "403            403        Institute of Control Sciences         403\n",
      "404            404  University of California - Berkeley         404\n",
      "405            405                 University of Lisbon         405\n",
      "406            406              University of Cambridge         406\n",
      "\n",
      "[407 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "Fake_has_table=Chord.fake_hash_table\n",
    "print(Fake_has_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave Circle κάποιων κόμβων"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN is -->12\n",
      "NN is -->12\n",
      "NN is -->12\n",
      "NN is -->309\n",
      "NN is -->86\n",
      "NN is -->170\n",
      "NN is -->384\n",
      "NN is -->398\n",
      "NN is -->398\n",
      "NN is -->0\n"
     ]
    }
   ],
   "source": [
    "Chord.leave_circle(11)\n",
    "Chord.leave_circle(12)\n",
    "Chord.leave_circle(13)\n",
    "Chord.leave_circle(311)\n",
    "Chord.leave_circle(88)\n",
    "Chord.leave_circle(173)\n",
    "Chord.leave_circle(389)\n",
    "Chord.leave_circle(404)\n",
    "Chord.leave_circle(405)\n",
    "Chord.leave_circle(406)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join Circle κάποιων κόμβων"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Chord.join_circle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LookUps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The key is --> 406\n",
      "Searching 0 fingertable\n",
      "0      1\n",
      "1      2\n",
      "2      4\n",
      "3      8\n",
      "4     16\n",
      "5     32\n",
      "6     64\n",
      "7    128\n",
      "8    256\n",
      "Name: successors, dtype: int64\n",
      "Max row = 256\n",
      "Searching 256 fingertable\n",
      "0    257\n",
      "1    258\n",
      "2    260\n",
      "3    264\n",
      "4    272\n",
      "5    288\n",
      "6    320\n",
      "7    384\n",
      "8    105\n",
      "Name: successors, dtype: int64\n",
      "Max row = 384\n",
      "Searching 384 fingertable\n",
      "0    385\n",
      "1    386\n",
      "2    388\n",
      "3    392\n",
      "4    400\n",
      "5      9\n",
      "6     41\n",
      "7    105\n",
      "8    233\n",
      "Name: successors, dtype: int64\n",
      "Max row = 400\n",
      "Searching 400 fingertable\n",
      "0    401\n",
      "1    402\n",
      "2    406\n",
      "3      1\n",
      "4      9\n",
      "5     25\n",
      "6     57\n",
      "7    121\n",
      "8    249\n",
      "Name: successors, dtype: int64\n",
      "                                    Name  Awards                institute\n",
      "1                           Rediet Abebe       3  University of Cambridge\n",
      "2                       Rosemary Candlin       0  University of Cambridge\n",
      "3                    Christopher J. Date       0  University of Cambridge\n",
      "4               Charlotte Froese Fischer       4  University of Cambridge\n",
      "5                        Geoffrey Hinton       9  University of Cambridge\n",
      "6                          Mathai Joseph       5  University of Cambridge\n",
      "7                          Derek McAuley       1  University of Cambridge\n",
      "8                           Alan Mycroft       0  University of Cambridge\n",
      "9                          Mike Paterson      10  University of Cambridge\n",
      "10                    Simon Peyton Jones       2  University of Cambridge\n",
      "11                     Cicely Popplewell       0  University of Cambridge\n",
      "12  Martin Richards (computer scientist)       2  University of Cambridge\n",
      "13                  C. J. van Rijsbergen       0  University of Cambridge\n",
      "14                     Bjarne Stroustrup      11  University of Cambridge\n",
      "15                        Chai Keong Toh       3  University of Cambridge\n",
      "16                        Leslie Valiant       6  University of Cambridge\n",
      "17    David Wheeler (computer scientist)       6  University of Cambridge\n",
      "18                          Yorick Wilks      19  University of Cambridge\n",
      "19                         Sophie Wilson       6  University of Cambridge\n",
      "20                          Neil Wiseman       0  University of Cambridge\n",
      "21                      Beatrice Worsley       0  University of Cambridge\n"
     ]
    }
   ],
   "source": [
    "Chord.lookup(\"University of Cambridge\",0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
